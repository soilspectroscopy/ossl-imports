---
title: "Dataset import: Africa Soil Information Service (AfSIS-I) SSL"
author: "Jose Lucas Safanelli (jsafanelli@woodwellclimate.org), Tomislav Hengl (tom.hengl@opengeohub.org), Jonathan Sanderman (jsanderman@woodwellclimate.org) - "
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  github_document:
    toc: true
    toc_depth: 4
bibliography: ../../tex/refs.bib
csl: ../../tex/apa.csl  
fig_caption: yes
link-citations: yes
twitter-handle: soilspec
header-includes:
- \usepackage{caption}
editor_options: 
  markdown: 
    wrap: 72
---

[<img src="../../img/soilspec4gg-logo_fc.png" alt="SoilSpec4GG logo" width="250"/>](https://soilspectroscopy.org/)

[<img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" />](http://creativecommons.org/licenses/by-sa/4.0/)

This work is licensed under a [Creative Commons Attribution-ShareAlike 4.0 International License](http://creativecommons.org/licenses/by-sa/4.0/).

```{r setup, include=FALSE}
library(captioner)
fig_nums <- captioner(prefix = "Fig.")
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
options(scipen = 999)
```

## AfSIS-1 inputs

Part of: <https://github.com/soilspectroscopy>  
Project: [Soil Spectroscopy for Global
Good](https://soilspectroscopy.org)  
Last update: `r Sys.Date()`  
Dataset: [AFSIS1.SSL](https://soilspectroscopy.github.io/ossl-manual/soil-spectroscopy-tools-and-users.html#afsis1.ssl)

Mid-Infrared Spectra (MIRS) from AfSIS1 Soil and Plant Spectroscopy Laboratory Africa Soil Information Service (AfSIS) Phase I 2009-2013. Described in detail in @towett2015total and @Vagen_2020.

The dataset has two versions one published via the [World Agroforestry website](https://doi.org/10.34725/DVN/QXCWP1), one via AWS (<https://registry.opendata.aws/afsis/>). A copy of AfSIS SSL data is also available via <https://github.com/laura-summerauer/ssl-central-africa>.

```{r packages, include=TRUE, echo=FALSE, eval=TRUE}
packages <- c("tidyverse", "prospectr", "measurements", "readxl", "stringr",
              "olctools", "openssl", "tmap", "sf", "skimr", "lubridate",
              "googledrive", "googlesheets4", "data.table", "doMC", "tictoc", "qs")
new.packages <- packages[!(packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
invisible(lapply(packages, library, character.only = TRUE))
source("../../R-code/functions/SSL_functions.R")
```

Directory/folder path
```{r}
dir = "/mnt/soilspec4gg/ossl/dataset/AFSIS/"
tic()
```

## Data import

### Soil site information

```{r soilsite, include=TRUE, echo=TRUE, eval=TRUE}
# AfIS1 site data
afsis1.reference = fread(paste0(dir, "/AfSIS_reference.csv"))

afsis1.reference <- afsis1.reference %>%
  select(-Remarks) %>%
  rename(id.layer_local_c = `Batch and labid`,
         layer.sequence_usda_uint16 = HORI,
         layer.upper.depth_usda_cm = BTOP,
         layer.lower.depth_usda_cm = BBOT) %>%
  mutate(`Long: sec` = ifelse(is.na(`Long: sec`), 0, `Long: sec`),
         `Lat: sec` = ifelse(is.na(`Lat: sec`), 0, `Lat: sec`)) %>%
  mutate(lat = ifelse(`N / S`=="South",
                      paste0("-", `Lat: degr`, " ", `Lat: min`, " ", `Lat: sec`),
                      paste0(`Lat: degr`, " ", `Lat: min`, " ", `Lat: sec`)),
         lon = ifelse(`E / W`=="West",
                      paste0("-", `Long: degr`, " ", `Long: min`, " ", `Long: sec`),
                      paste0(`Long: degr`, " ", `Long: min`, " ", `Long: sec`))) %>%
  select(id.layer_local_c, Plotcode, layer.sequence_usda_uint16,
         layer.upper.depth_usda_cm, layer.lower.depth_usda_cm,
         lat, lon) %>%
  mutate(lat = ifelse(grepl("NA", lat), NA, lat),
         lon = ifelse(grepl("NA", lon), NA, lon)) %>%
  mutate(lat = measurements::conv_unit(lat, from = 'deg_min_sec', to = 'dec_deg'),
         lon = measurements::conv_unit(lon, from = 'deg_min_sec', to = 'dec_deg'))

# Joining both datasets
afsis1.sitedata <- afsis1.reference %>%
  left_join(isis.sitedata, by = "Plotcode") %>%
  mutate(longitude.point_wgs84_dd = ifelse(is.na(lon), as.numeric(long2), as.numeric(lon)),
         latitude.point_wgs84_dd = ifelse(is.na(lat), as.numeric(lat2), as.numeric(lat)),
         site_obsdate = lubridate::ymd(paste0(site_obsdate, "-01-01"))) %>%
  rename(id.dataset.site_ascii_c = Plotcode,
         observation.date.begin_iso.8601_yyyy.mm.dd = site_obsdate) %>%
  mutate(observation.date.end_iso.8601_yyyy.mm.dd = observation.date.begin_iso.8601_yyyy.mm.dd) %>%
  select(id.layer_local_c, latitude.point_wgs84_dd, longitude.point_wgs84_dd,
         id.dataset.site_ascii_c, observation.date.begin_iso.8601_yyyy.mm.dd, observation.date.end_iso.8601_yyyy.mm.dd,
         layer.sequence_usda_uint16, layer.upper.depth_usda_cm, layer.lower.depth_usda_cm, pedon.taxa_usda_c) %>% 
  mutate(id.project_ascii_c = "ICRAF-ISRIC Soil Spectral Library",
         id.layer_uuid_c = openssl::md5(as.character(id.layer_local_c)),
         id.location_olc_c = olctools::encode_olc(latitude.point_wgs84_dd, longitude.point_wgs84_dd, 10),
         layer.texture_usda_c = "",
         horizon.designation_usda_c = "",
         longitude.county_wgs84_dd = NA,
         latitude.county_wgs84_dd = NA,
         location.point.error_any_m = 30,
         location.country_iso.3166_c = "",
         observation.ogc.schema.title_ogc_txt = "Open Soil Spectroscopy Library",
         observation.ogc.schema_idn_url = "https://soilspectroscopy.github.io",
         surveyor.title_utf8_txt = "Stephan Mantel",
         surveyor.contact_ietf_email = "stephan.mantel@wur.nl",
         surveyor.address_utf8_txt = "ICRAF, PO Box 30677, Nairobi, 00100, Kenya",
         dataset.title_utf8_txt = "ICRAF-ISRIC Soil Spectral Library",
         dataset.owner_utf8_txt = "World Agroforestry Centre (ICRAF) / ISRIC - World Soil Information",
         dataset.code_ascii_c = "afsis1",
         dataset.address_idn_url = "https://www.isric.org/explore/ISRIC-collections",
         dataset.doi_idf_url = "https://doi.org/10.34725/DVN/MFHA9C",
         dataset.license.title_ascii_txt = "CC-BY",
         dataset.license.address_idn_url = "https://creativecommons.org/licenses/by/4.0/",
         dataset.contact.name_utf8_txt = "Keith Shepherd",
         dataset.contact_ietf_email = "afsis.info@africasoils.net")

# Removing duplicates
# afsis1.sitedata %>%
#   group_by(id.layer_local_c) %>%
#   summarise(repeats = n()) %>%
#   group_by(repeats) %>%
#   summarise(count = n())

dupli.ids <- afsis1.sitedata %>%
  group_by(id.layer_local_c) %>%
  summarise(repeats = n()) %>%
  filter(repeats > 1) %>%
  pull(id.layer_local_c)

afsis1.sitedata <- afsis1.sitedata %>%
  filter(!(id.layer_local_c %in% dupli.ids)) %>%
  as.data.frame()

# Saving version to dataset root dir
site.qs = paste0(dir, "/ossl_soilsite_v1.2.qs")
qs::qsave(afsis1.sitedata, site.qs, preset = "high")
```

### Soil lab information

NOTE: The code chunk below this paragraph is hidden. Just run once for getting the original names of soil properties, descriptions, data types, and units. Run once and upload to Google Sheet for formatting and integrating with the OSSL. Requires Google authentication.

```{r, eval=FALSE, echo=TRUE}
# Getting soillab original variables
variables.file = readr::read_csv(paste0(dir, "/AfSIS_reference.csv"))

# They all have the same soil properties
soillab.names <- variables.file %>%
  names(.) %>%
  tibble(original_name = .) %>%
  dplyr::mutate(table = 'AfSIS_reference.csv', .before = 1) %>%
  dplyr::mutate(import = '', ossl_name = '', .after = original_name) %>%
  dplyr::mutate(comment = '')

readr::write_csv(soillab.names, paste0(getwd(), "/afis_soillab_names.csv"))

# Uploading to google sheet

# FACT CIN folder. Get ID for soildata importing table
googledrive::drive_ls(as_id("0AHDIWmLAj40_Uk9PVA"))

OSSL.soildata.importing <- "19LeILz9AEnKVK7GK0ZbK3CCr2RfeP-gSWn5VpY8ETVM"

# Checking metadata
googlesheets4::as_sheets_id(OSSL.soildata.importing)

# Checking readme
googlesheets4::read_sheet(OSSL.soildata.importing, sheet = 'readme')

# Preparing soillab.names
upload <- dplyr::as_tibble(soillab.names)

# Uploading
googlesheets4::write_sheet(upload, ss = OSSL.soildata.importing, sheet = "AFSIS")

# Checking metadata
googlesheets4::as_sheets_id(OSSL.soildata.importing)
```

NOTE: The code chunk below this paragraph is hidden. Run once for importing the transformation rules. The table can be edited online at Google Sheets. A copy is downloaded to github for archiving.
```{r soilab_download, include=FALSE, echo=FALSE, eval=FALSE}
# Downloading from google sheet

# FACT CIN folder id
listed.table <- googledrive::drive_ls(as_id("0AHDIWmLAj40_Uk9PVA"),
                                      pattern = "OSSL_tab2_soildata_importing")

OSSL.soildata.importing <- listed.table[[1,"id"]]

# Checking metadata
googlesheets4::as_sheets_id(OSSL.soildata.importing)

# Preparing soillab.names
transvalues <- googlesheets4::read_sheet(OSSL.soildata.importing, sheet = "AFSIS") %>%
  filter(import == TRUE) %>%
  select(contains(c("table", "id", "original_name", "ossl_")))

# Saving to folder
write_csv(transvalues, paste0(getwd(), "/OSSL_transvalues.csv"))
```

Reading AFSIS1-to-OSSL transformation values:
```{r soilab_transvalues, include=TRUE, echo=TRUE, eval=TRUE}
transvalues <- read_csv(paste0(getwd(), "/OSSL_transvalues.csv"))
knitr::kable(transvalues)
```

Preparing soil data from different files:
```{r soilab_preparation, include=TRUE, echo=TRUE, eval=TRUE}
afsis1.reference = fread(paste0(dir, "/ICRAF_ISRIC_reference_data.csv"))

# Harmonization of names and units
analytes.old.names <- transvalues %>%
  filter(table == "ICRAF_ISRIC_reference_data.csv") %>%
  pull(original_name)

analytes.new.names <- transvalues %>%
  filter(table == "ICRAF_ISRIC_reference_data.csv") %>%
  pull(ossl_name)

# Selecting and renaming
afsis1.soildata <- afsis1.reference %>%
  select(-Remarks) %>%
  rename(id.layer_local_c = `Batch and labid`) %>%
  select(id.layer_local_c, all_of(analytes.old.names)) %>%
  rename_with(~analytes.new.names, analytes.old.names)

# Removing duplicates
# afsis1.soildata %>%
#   group_by(id.layer_local_c) %>%
#   summarise(repeats = n()) %>%
#   group_by(repeats) %>%
#   summarise(count = n())

dupli.ids <- afsis1.soildata %>%
  group_by(id.layer_local_c) %>%
  summarise(repeats = n()) %>%
  filter(repeats > 1) %>%
  pull(id.layer_local_c)

afsis1.soildata <- afsis1.soildata %>%
  filter(!(id.layer_local_c %in% dupli.ids)) %>%
  as.data.frame()

# Getting the formulas
functions.list <- transvalues %>%
  filter(table == "ICRAF_ISRIC_reference_data.csv") %>%
  mutate(ossl_name = factor(ossl_name, levels = names(afsis1.soildata))) %>%
  arrange(ossl_name) %>%
  pull(ossl_convert) %>%
  c("x", .)

# Applying transformation rules
afsis1.soildata.trans <- transform_values(df = afsis1.soildata,
                                               out.name = names(afsis1.soildata),
                                               in.name = names(afsis1.soildata),
                                               fun.lst = functions.list)

# Final soillab data
afsis1.soildata <- afsis1.soildata.trans

# Checking total number of observations
afsis1.soildata %>%
  distinct(id.layer_local_c) %>%
  summarise(count = n())
  
# Saving version to dataset root dir
soillab.qs = paste0(dir, "/ossl_soillab_v1.2.qs")
qs::qsave(afsis1.soildata, soillab.qs, preset = "high")
```

### Mid-infrared spectroscopy data

```{r mir, include=TRUE, echo=TRUE, eval=TRUE}
# Floating wavenumbers
mir.scans <- fread(paste0(dir, "/ICRAF_ISRIC_MIR_spectra.csv"), header = TRUE)

old.names <- names(mir.scans)
new.names <- gsub("m", "", old.names)

afsis1.mir <- mir.scans %>%
  rename_with(~new.names, old.names) %>%
  rename(id.layer_local_c = SSN)

# Need to resample spectra
old.wavenumber <- na.omit(as.numeric(names(afsis1.mir)))
new.wavenumbers <- rev(seq(600, 4000, by = 2))

afsis1.mir <- afsis1.mir %>%
  select(-id.layer_local_c) %>%
  as.matrix() %>%
  prospectr::resample(X = ., wav = old.wavenumber, new.wav = new.wavenumbers, interpol = "spline") %>%
  as_tibble() %>%
  bind_cols({afsis1.mir %>%
      select(id.layer_local_c)}, .) %>%
  select(id.layer_local_c, as.character(rev(new.wavenumbers)))

afsis1.mir <- afsis1.mir %>%
  group_by(id.layer_local_c) %>%
  summarise_all(mean)

# Spectral consistency analysis
cl = makeCluster(mc <- getOption("cl.cores", data.table::getDTthreads()))

# Gaps
scans.na.gaps <- afsis1.mir %>%
  select(-id.layer_local_c) %>%
  parallel::parRapply(cl, ., function(x) round(100*(sum(is.na(x)))/(length(x)), 2)) %>%
  tibble(proportion_NA = .) %>%
  bind_cols({afsis1.mir %>% select(id.layer_local_c)}, .)

# Extreme negative - irreversible erratic patterns
scans.extreme.neg <- afsis1.mir %>%
  select(-id.layer_local_c) %>%
  parallel::parRapply(cl, ., function(x) {
    round(100*(sum(x < -1, na.rm=TRUE))/(length(x)), 2)
  }) %>%
  tibble(proportion_lower0 = .) %>%
  bind_cols({afsis1.mir %>% select(id.layer_local_c)}, .)

# Extreme positive, irreversible erratic patterns
scans.extreme.pos <- afsis1.mir %>%
  select(-id.layer_local_c) %>%
  parallel::parRapply(cl, ., function(x) {
    round(100*(sum(x > 5, na.rm=TRUE))/(length(x)), 2)
  }) %>%
  tibble(proportion_higherAbs5 = .) %>%
  bind_cols({afsis1.mir %>% select(id.layer_local_c)}, .)

stopCluster(cl)

# Consistency summary - problematic scans
scans.summary <- scans.na.gaps %>%
  left_join(scans.extreme.neg, by = "id.layer_local_c") %>%
  left_join(scans.extreme.pos, by = "id.layer_local_c")

scans.summary %>%
  select(-id.layer_local_c) %>%
  pivot_longer(everything(), names_to = "check", values_to = "value") %>%
  filter(value > 0) %>%
  group_by(check) %>%
  summarise(count = n())

# Checking duplicates
dupli.ids <- afsis1.mir %>%
  group_by(id.layer_local_c) %>%
  summarise(repeats = n()) %>%
  filter(repeats > 1) %>%
  pull(id.layer_local_c)

afsis1.mir <- afsis1.mir %>%
  filter(!(id.layer_local_c %in% dupli.ids))

# # These few scans with extreme values are filled with interpolation
# target.wavenumbers <- rev(seq(600, 4000, by = 2))
# 
# afsis1.mir.clean <- afsis1.mir %>%
#   pivot_longer(-id.layer_local_c, names_to = "wavenumber", values_to = "absorbance") %>%
#   mutate(absorbance = ifelse(absorbance > 3.5, NA, absorbance)) %>%
#   group_by(id.layer_local_c) %>%
#   mutate(absorbance = approx(wavenumber, absorbance, target.wavenumbers)$y) %>%
#   pivot_wider(names_from = "wavenumber", values_from = "absorbance")

# Renaming
old.wavenumbers <- seq(600, 4000, by = 2)
new.wavenumbers <- paste0("scan_mir.", old.wavenumbers, "_abs")

afsis1.mir <- afsis1.mir %>%
  rename_with(~new.wavenumbers, as.character(old.wavenumbers))

# Preparing metadata
afsis1.mir.metadata <- afsis1.mir %>%
  select(id.layer_local_c) %>%
  mutate(id.scan_local_c = id.layer_local_c) %>%
  mutate(scan.mir.date.begin_iso.8601_yyyy.mm.dd = ymd("2004-02-01"),
         scan.mir.date.end_iso.8601_yyyy.mm.dd = ymd("2004-11-01"),
         scan.mir.model.name_utf8_txt = "Bruker Vertex 70 with HTS-XT accessory",
         scan.mir.model.code_any_c = "Bruker_Vertex_70.HTS.XT",
         scan.mir.method.light.source_any_c = "",
         scan.mir.method.preparation_any_c = "",
         scan.mir.license.title_ascii_txt = "CC-BY",
         scan.mir.license.address_idn_url = "https://creativecommons.org/licenses/by/4.0/",
         scan.mir.doi_idf_c = "https://doi.org/10.34725/DVN/MFHA9C",
         scan.mir.contact.name_utf8_txt = "Keith Shepherd",
         scan.mir.contact.email_ietf_email = "afsis.info@africasoils.net")

# Final preparation
afsis1.mir.export <- afsis1.mir.metadata %>%
  left_join(afsis1.mir, by = "id.layer_local_c")

# Saving version to dataset root dir
soilmir.qs = paste0(dir, "/ossl_mir_v1.2.qs")
qs::qsave(afsis1.mir.export, soilmir.qs, preset = "high")
```

### Visible and Near-infrared spectroscopy data

Reading the ViSNIR scans. The spectra is in absorbance log units and placed in a matrix inside the dataframe.
```{r visnir, include=TRUE, echo=TRUE, eval=TRUE}
# Floating wavenumbers
visnir.scans <- fread(paste0(dir, "/ICRAF_ISRIC_VNIR_spectra.csv"), header = TRUE)

old.names <- names(visnir.scans)
new.names <- gsub("W", "", old.names)

afsis1.visnir <- visnir.scans %>%
  rename_with(~new.names, old.names) %>%
  rename(id.layer_local_c = Batch.Labid)

# Need to resample spectra
old.wavelengths <- na.omit(as.numeric(names(afsis1.visnir)))
new.wavelengths <- rev(seq(350, 2500, by = 2))

afsis1.visnir <- afsis1.visnir %>%
  select(-id.layer_local_c) %>%
  as.matrix() %>%
  prospectr::resample(X = ., wav = old.wavelengths, new.wav = new.wavelengths, interpol = "spline") %>%
  as_tibble() %>%
  bind_cols({afsis1.visnir %>%
      select(id.layer_local_c)}, .) %>%
  select(id.layer_local_c, as.character(rev(new.wavelengths)))

afsis1.visnir <- afsis1.visnir %>%
  group_by(id.layer_local_c) %>%
  summarise_all(mean)

# Spectral consistency analysis
cl = makeCluster(mc <- getOption("cl.cores", data.table::getDTthreads()))

# Gaps
scans.na.gaps <- afsis1.visnir %>%
  select(all_of(as.character(new.wavelengths))) %>%
  parallel::parRapply(cl, ., function(x) round(100*(sum(is.na(x)))/(length(x)), 2)) %>%
  tibble(proportion_NA = .) %>%
  bind_cols({afsis1.visnir %>% select(id.layer_local_c)}, .)

# Extreme negative
scans.extreme.neg <- afsis1.visnir %>%
  select(all_of(as.character(new.wavelengths))) %>%
  parallel::parRapply(cl, ., function(x) {
    round(100*(sum(x < 0, na.rm=TRUE))/(length(x)), 2)
  }) %>%
  tibble(proportion_lower0 = .) %>%
  bind_cols({afsis1.visnir %>% select(id.layer_local_c)}, .)

# Extreme positive
scans.extreme.pos <- afsis1.visnir %>%
  select(all_of(as.character(new.wavelengths))) %>%
  parallel::parRapply(cl, ., function(x) {
    round(100*(sum(x > 1, na.rm=TRUE))/(length(x)), 2)
  }) %>%
  tibble(proportion_higherRef1 = .) %>%
  bind_cols({afsis1.visnir %>% select(id.layer_local_c)}, .)

stopCluster(cl)

# Consistency summary - problematic scans
scans.summary <- scans.na.gaps %>%
  left_join(scans.extreme.neg, by = "id.layer_local_c") %>%
  left_join(scans.extreme.pos, by = "id.layer_local_c")

# Will omit this. Preprocessing handle baseline offset
scans.summary %>%
  select(-id.layer_local_c) %>%
  pivot_longer(everything(), names_to = "check", values_to = "value") %>%
  filter(value > 0) %>%
  group_by(check) %>%
  summarise(count = n())

# Checking duplicates
dupli.ids <- afsis1.visnir %>%
  group_by(id.layer_local_c) %>%
  summarise(repeats = n()) %>%
  filter(repeats > 1) %>%
  pull(id.layer_local_c)

afsis1.visnir <- afsis1.visnir %>%
  filter(!(id.layer_local_c %in% dupli.ids))

# Renaming
old.wavelengths <- seq(350, 2500, by = 2)
new.wavelengths <- paste0("scan_visnir.", old.wavelengths, "_ref")

afsis1.visnir <- afsis1.visnir %>%
  rename_with(~new.wavelengths, as.character(old.wavelengths))

# Preparing metadata
afsis1.visnir.metadata <- afsis1.visnir %>%
  select(id.layer_local_c) %>%
  mutate(id.scan_local_c = id.layer_local_c) %>%
  mutate(scan.visnir.date.begin_iso.8601_yyyy.mm.dd = ymd("2004-02-01"),
         scan.visnir.date.end_iso.8601_yyyy.mm.dd = ymd("2004-11-01"),
         scan.visnir.model.name_utf8_txt = "ASD FieldSpec Pro FR",
         scan.visnir.model.code_any_c = "ASD_FieldSpec_FR",
         scan.visnir.method.light.source_any_c = "4.5 W halogen lamp",
         scan.visnir.method.preparation_any_c = "",
         scan.visnir.license.title_ascii_txt = "CC-BY",
         scan.visnir.license.address_idn_url = "https://creativecommons.org/licenses/by/4.0/",
         scan.visnir.doi_idf_c = "https://doi.org/10.34725/DVN/MFHA9C",
         scan.visnir.contact.name_utf8_txt = "Keith Shepherd",
         scan.visnir.contact.email_ietf_email = "afsis.info@africasoils.net")

# Final preparation
afsis1.visnir.export <- afsis1.visnir.metadata %>%
  left_join(afsis1.visnir, by = "id.layer_local_c")

# Saving version to dataset root dir
soilvisnir.qs = paste0(dir, "/ossl_visnir_v1.2.qs")
qs::qsave(afsis1.visnir.export, soilvisnir.qs, preset = "high")
```

The final table must be joined as:

- VisNIR is used as first reference.
- It is fully joined with MIR.
- The result is left joined with the site and soil lab data. This drop data without any scan.

The availabilty of data is summarised below:
```{r bind_test, include=TRUE, echo=TRUE, eval=TRUE}
# Taking a few representative columns for checking the consistency of joins
afsis1.availability <- afsis1.visnir %>%
  select(id.layer_local_c, scan_visnir.450_ref) %>%
  full_join({afsis1.mir %>%
      select(id.layer_local_c, scan_mir.600_abs)}, by = "id.layer_local_c") %>%
  left_join({afsis1.sitedata %>%
      select(id.layer_local_c, layer.upper.depth_usda_cm)}, by = "id.layer_local_c") %>%
  left_join({afsis1.soildata %>%
      select(id.layer_local_c, ph.h2o_usda.a268_index)}, by = "id.layer_local_c") %>%
  filter(!is.na(id.layer_local_c))

# Availability of information from afsis1
afsis1.availability %>%
  mutate_all(as.character) %>%
  pivot_longer(everything(), names_to = "column", values_to = "value") %>%
  filter(!is.na(value)) %>%
  group_by(column) %>%
  summarise(count = n())

# Repeats check - Duplicates are dropped
afsis1.availability %>%
  mutate_all(as.character) %>%
  select(id.layer_local_c) %>%
  pivot_longer(everything(), names_to = "column", values_to = "value") %>%
  group_by(column, value) %>%
  summarise(repeats = n()) %>%
  group_by(column, repeats) %>%
  summarise(count = n())
```

This summary shows that, at total, about 40k observations are available. Some rows have both MIR and VisNIR scans, many not.

NOTE: As the duplicated layers represent a minor fraction (n=26) of the database, they will be dropped when binding all the datasets for making the OSSL level 0.

Plotting sites map:
```{r map, include=TRUE, echo=TRUE, eval=TRUE}
data("World")

points <- afsis1.sitedata %>%
  filter(!is.na(longitude.point_wgs84_dd)) %>%
  st_as_sf(coords = c('longitude.point_wgs84_dd', 'latitude.point_wgs84_dd'), crs = 4326)

tmap_mode("plot")

tm_shape(World) +
  tm_polygons('#f0f0f0f0', border.alpha = 0.2) +
  tm_shape(points) +
  tm_dots()
```

Soil analytical data summary:
```{r summary, include=TRUE, echo=TRUE, eval=TRUE}
afsis1.soildata %>%
  mutate(id.layer_local_c = factor(id.layer_local_c)) %>%
  skimr::skim() %>%
  dplyr::select(-numeric.hist, -complete_rate)
```

MIR spectral visualization:
```{r mir_plot, include=TRUE, echo=TRUE, eval=TRUE}
set.seed(1993)
afsis1.mir %>%
  sample_n(500) %>%
  select(all_of(c("id.layer_local_c")), starts_with("scan_mir.")) %>%
  tidyr::pivot_longer(-all_of(c("id.layer_local_c")),
                      names_to = "wavenumber", values_to = "absorbance") %>%
  dplyr::mutate(wavenumber = gsub("scan_mir.|_abs", "", wavenumber)) %>%
  dplyr::mutate(wavenumber = as.numeric(wavenumber)) %>%
  ggplot(aes(x = wavenumber, y = absorbance, group = id.layer_local_c)) +
  geom_line(alpha = 0.1) +
  scale_x_continuous(breaks = c(600, 1200, 1800, 2400, 3000, 3600, 4000)) +
  labs(x = bquote("Wavenumber"~(cm^-1)), y = "Absorbance") +
  theme_light()
```

ViSNIR spectral visualization:
```{r visnir_plot, include=TRUE, echo=TRUE, eval=TRUE}
set.seed(1993)
afsis1.visnir %>%
  select(all_of(c("id.layer_local_c")), starts_with("scan_visnir.")) %>%
  sample_n(500) %>%
  mutate_at(vars(starts_with("scan_visnir.")), as.numeric) %>%
  tidyr::pivot_longer(-all_of(c("id.layer_local_c")), names_to = "wavelength", values_to = "reflectance") %>%
  dplyr::mutate(wavelength = gsub("scan_visnir.|_ref", "", wavelength)) %>%
  dplyr::mutate(wavelength = as.numeric(wavelength)) %>%
  ggplot(aes(x = wavelength, y = reflectance, group = id.layer_local_c)) +
  geom_line(alpha = 0.1) +
  scale_x_continuous(breaks = c(350, 500, 1000, 1500, 2000, 2500)) +
  labs(x = bquote("Wavelength"~(nm)), y = "Reflectance") +
  theme_light()
```

```{r}
toc()
rm(list = ls())
gc()
```

## References
