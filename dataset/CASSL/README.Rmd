---
title: "Dataset import: The Central African soil spectral library"
author: "Jose Lucas Safanelli (jsafanelli@woodwellclimate.org), Tomislav Hengl (tom.hengl@opengeohub.org), Jonathan Sanderman (jsanderman@woodwellclimate.org) - "
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  github_document:
    toc: true
    toc_depth: 4
bibliography: ../../tex/refs.bib
csl: ../../tex/apa.csl  
fig_caption: yes
link-citations: yes
twitter-handle: soilspec
header-includes:
- \usepackage{caption}
editor_options: 
  markdown: 
    wrap: 72
---

[<img src="../../img/soilspec4gg-logo_fc.png" alt="SoilSpec4GG logo" width="250"/>](https://soilspectroscopy.org/)

[<img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" />](http://creativecommons.org/licenses/by-sa/4.0/)

This work is licensed under a [Creative Commons Attribution-ShareAlike 4.0 International License](http://creativecommons.org/licenses/by-sa/4.0/).

```{r setup, include=FALSE}
library(captioner)
fig_nums <- captioner(prefix = "Fig.")
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
options(scipen = 999)
```

## The central African soil spectral library inputs

Part of: <https://github.com/soilspectroscopy>  
Project: [Soil Spectroscopy for Global
Good](https://soilspectroscopy.org)  
Last update: `r Sys.Date()`  
Dataset: [CAF.SSL](https://soilspectroscopy.github.io/ossl-manual/soil-spectroscopy-tools-and-users.html#caf.ssl)

Mid-Infrared Spectra (MIRS) from The Central African SSL explained in detail in @summerauer2021central.
A copy of the dataset can be obtained from <https://github.com/laura-summerauer/ssl-central-africa>.

Input datasets:  
- `cssl_metadata_all.csv`: csv file with site information;  
- `cssl_metadata_all.csv`: csv file with soil information;  
- `cssl_spectra.csv`: MIR spectral scans;

```{r packages, include=TRUE, echo=FALSE, eval=TRUE}
packages <- c("tidyverse", "prospectr", "measurements", "readxl", "stringr",
              "olctools", "openssl", "tmap", "sf", "skimr", "lubridate",
              "googledrive", "googlesheets4", "data.table", "doMC", "tictoc", "qs")
new.packages <- packages[!(packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
invisible(lapply(packages, library, character.only = TRUE))
source("../../R-code/functions/SSL_functions.R")
```

Directory/folder path
```{r}
dir = "/mnt/soilspec4gg/ossl/dataset/CASSL/"
tic()
```

## Data import

### Soil site information

```{r}
caf.metadata <- fread(paste0(dir, "field_metadata/cssl_metadata_all.csv"), header = T)

caf.sitedata <- caf.metadata %>%
  select(sample_id, sample_location, country_code,
         sampling_date, sampling_layer, gps_long, gps_lat, gps_true) %>%
  rename(id.layer_local_c = sample_id,
         longitude.point_wgs84_dd = gps_long,
         latitude.point_wgs84_dd = gps_lat) %>%
  mutate(id.layer_local_c = as.character(id.layer_local_c)) %>%
  separate(sampling_layer, into = c("layer.upper.depth_usda_cm", "layer.lower.depth_usda_cm"), sep = "-") %>%
  mutate(layer.sequence_usda_uint16 = ifelse(layer.upper.depth_usda_cm == 0, 1, 2),
         location.point.error_any_m = ifelse(gps_true == "yes", 30, 1000)) %>%
  mutate(sampling_date = gsub("/", "-", sampling_date)) %>%
  mutate(sampling_date = case_when(is.na(sampling_date) ~ NA_character_,
                                   str_count(sampling_date, "-") == 2 ~ sampling_date,
                                   str_count(sampling_date, "-") == 1 &
                                     str_length(sampling_date) == 7 ~ paste0(sampling_date, "-01"),
                                   str_count(sampling_date, "-") == 1 &
                                     str_length(sampling_date) > 7 ~ paste0(str_sub(sampling_date, 1, 4), "-01-01"),
                                   str_count(sampling_date, "-") == 0 &
                                     str_length(sampling_date) == 4 ~paste0(str_sub(sampling_date, 1, 4), "-01-01"),
                                   TRUE ~ NA_character_), .after = sampling_date) %>%
  rename(observation.date.begin_iso.8601_yyyy.mm.dd = sampling_date) %>%
  mutate(observation.date.end_iso.8601_yyyy.mm.dd = observation.date.begin_iso.8601_yyyy.mm.dd) %>%
  select(id.layer_local_c, longitude.point_wgs84_dd, latitude.point_wgs84_dd, location.point.error_any_m,
         layer.sequence_usda_uint16, layer.upper.depth_usda_cm, layer.lower.depth_usda_cm,
         observation.date.begin_iso.8601_yyyy.mm.dd, observation.date.end_iso.8601_yyyy.mm.dd) %>%
  mutate(id.project_ascii_txt = "The Central African Soil Spectral Library",
         layer.texture_usda_txt = "",
         pedon.taxa_usda_txt = "",
         horizon.designation_usda_txt = "",
         longitude.county_wgs84_dd = NA,
         latitude.county_wgs84_dd = NA,
         location.country_iso.3166_txt = "",
         observation.ogc.schema.title_ogc_txt = "Open Soil Spectroscopy Library",
         observation.ogc.schema_idn_url = "https://soilspectroscopy.github.io",
         surveyor.title_utf8_txt = "Department of Environmental Systems Science, ETH Zurich, Zurich Switzerland",
         surveyor.contact_ietf_email = "laura.summerauer@usys.ethz.ch",
         surveyor.address_utf8_txt = "Department of Environmental Systems Science, ETH Zurich, Zurich Switzerland",
         dataset.title_utf8_txt = "The Central African Soil Spectral Library",
         dataset.owner_utf8_txt = "ETH Zurich",
         dataset.code_ascii_txt = "CAF.SSL",
         dataset.address_idn_url = "https://www.isric.org/explore/ISRIC-collections",
         dataset.doi_idf_url = "https://doi.org/10.5281/zenodo.4351254",
         dataset.license.title_ascii_txt = "CC-BY",
         dataset.license.address_idn_url = "https://creativecommons.org/licenses/by/4.0/",
         dataset.contact.name_utf8_txt = "Laura Summerauer",
         dataset.contact_ietf_email = "laura.summerauer@usys.ethz.ch") %>%
  mutate(id.layer_uuid_txt = openssl::md5(paste0(dataset.code_ascii_txt, id.layer_local_c)),
         id.location_olc_txt = olctools::encode_olc(latitude.point_wgs84_dd, longitude.point_wgs84_dd, 10),
         .after = id.project_ascii_txt) %>%
  mutate_at(vars(starts_with("id.")), as.character)

# Saving version to dataset root dir
site.qs = paste0(dir, "/ossl_soilsite_v1.2.qs")
qs::qsave(caf.sitedata, site.qs, preset = "high")
```

### Soil lab information

NOTE: The code chunk below this paragraph is hidden. Just run once for getting the original names of soil properties, descriptions, data types, and units. Run once and upload to Google Sheet for formatting and integrating with the OSSL. Requires Google authentication.

<!-- ```{r, eval=FALSE, echo=TRUE} -->
<!-- # Getting soillab original variables -->

<!-- soillab.names <- cassl.soildata %>% -->
<!--   names(.) %>% -->
<!--   tibble(original_name = .) %>% -->
<!--   dplyr::mutate(table = 'cssl_refdata_all', .before = 1) %>% -->
<!--   dplyr::mutate(import = '', ossl_name = '', .after = original_name) %>% -->
<!--   dplyr::mutate(comment = '') -->

<!-- readr::write_csv(soillab.names, paste0(getwd(), "/cassl_soillab_names.csv")) -->

<!-- # Uploading to google sheet -->

<!-- # FACT CIN folder. Get ID for soildata importing table -->
<!-- googledrive::drive_ls(as_id("0AHDIWmLAj40_Uk9PVA")) -->

<!-- OSSL.soildata.importing <- "19LeILz9AEnKVK7GK0ZbK3CCr2RfeP-gSWn5VpY8ETVM" -->

<!-- # Checking metadata -->
<!-- googlesheets4::as_sheets_id(OSSL.soildata.importing) -->

<!-- # Checking readme -->
<!-- googlesheets4::read_sheet(OSSL.soildata.importing, sheet = 'readme') -->

<!-- # Preparing soillab.names -->
<!-- upload <- dplyr::as_tibble(soillab.names) -->

<!-- # Uploading -->
<!-- googlesheets4::write_sheet(upload, ss = OSSL.soildata.importing, sheet = "CAF") -->

<!-- # Checking metadata -->
<!-- googlesheets4::as_sheets_id(OSSL.soildata.importing) -->
<!-- ``` -->

NOTE: The code chunk below this paragraph is hidden. Run once for importing the transformation rules. The table can be edited online at Google Sheets. A copy is downloaded to github for archiving.

<!-- ```{r soilab_download, include=FALSE, echo=FALSE, eval=FALSE} -->
<!-- # Downloading from google sheet -->

<!-- # FACT CIN folder id -->
<!-- listed.table <- googledrive::drive_ls(as_id("0AHDIWmLAj40_Uk9PVA"), -->
<!--                                       pattern = "OSSL_tab2_soildata_importing") -->

<!-- OSSL.soildata.importing <- listed.table[[1,"id"]] -->

<!-- # Checking metadata -->
<!-- googlesheets4::as_sheets_id(OSSL.soildata.importing) -->

<!-- # Preparing soillab.names -->
<!-- transvalues <- googlesheets4::read_sheet(OSSL.soildata.importing, sheet = "CAF") %>% -->
<!--   filter(import == TRUE) %>% -->
<!--   select(contains(c("table", "id", "original_name", "ossl_"))) -->

<!-- # Saving to folder -->
<!-- write_csv(transvalues, paste0(getwd(), "/OSSL_transvalues.csv")) -->
<!-- ``` -->

Reading AFSIS1-to-OSSL transformation values:
```{r soilab_transvalues, include=TRUE, echo=TRUE, eval=TRUE}
transvalues <- read_csv(paste0(getwd(), "/OSSL_transvalues.csv"))
knitr::kable(transvalues)
```

Preparing soil data from different files:
```{r soilab_preparation, include=TRUE, echo=TRUE, eval=TRUE}
caf.reference <- fread(paste0(dir, "reference_data/cssl_refdata_all.csv"), header = T)

# Harmonization of names and units
analytes.old.names <- transvalues %>%
  filter(table == "cssl_refdata_all") %>%
  pull(original_name)

analytes.new.names <- transvalues %>%
  filter(table == "cssl_refdata_all") %>%
  pull(ossl_name)

# Selecting and renaming
caf.soildata <- caf.reference %>%
  rename(id.layer_local_c = sample_id) %>%
  select(id.layer_local_c, all_of(analytes.old.names)) %>%
  rename_with(~analytes.new.names, analytes.old.names) %>%
  mutate(id.layer_local_c = as.character(id.layer_local_c)) %>%
  as.data.frame()

# Removing duplicates
# caf.soildata %>%
#   group_by(id.layer_local_c) %>%
#   summarise(repeats = n()) %>%
#   group_by(repeats) %>%
#   summarise(count = n())

# Getting the formulas
functions.list <- transvalues %>%
  filter(table == "cssl_refdata_all") %>%
  mutate(ossl_name = factor(ossl_name, levels = names(caf.soildata))) %>%
  arrange(ossl_name) %>%
  pull(ossl_convert) %>%
  c("x", .)

# Applying transformation rules
caf.soildata.trans <- transform_values(df = caf.soildata,
                                       out.name = names(caf.soildata),
                                       in.name = names(caf.soildata),
                                       fun.lst = functions.list)

# Final soillab data
caf.soildata <- caf.soildata.trans %>%
  mutate_at(vars(starts_with("id.")), as.character)

# Checking total number of observations
caf.soildata %>%
  distinct(id.layer_local_c) %>%
  summarise(count = n())
  
# Saving version to dataset root dir
soillab.qs = paste0(dir, "/ossl_soillab_v1.2.qs")
qs::qsave(caf.soildata, soillab.qs, preset = "high")
```

### Mid-infrared spectroscopy data

```{r mir, include=TRUE, echo=TRUE, eval=TRUE}
# Floating wavenumbers
caf.spectra <- fread(paste0(dir, "spectra_data/cssl_spectra.csv"), header = T)

# Renaming
old.names <- names(caf.spectra)

caf.mir <- caf.spectra %>%
  rename(id.layer_local_c = sample_id) %>%
  mutate(id.layer_local_c = as.character(id.layer_local_c)) %>%
  mutate_at(vars(all_of(old.names[-1])), as.numeric)

# Need to resample spectra
old.wavenumber <- na.omit(as.numeric(names(caf.mir)))
new.wavenumbers <- rev(seq(600, 4000, by = 2))

caf.mir <- caf.mir %>%
  select(-id.layer_local_c) %>%
  as.matrix() %>%
  prospectr::resample(X = ., wav = old.wavenumber, new.wav = new.wavenumbers, interpol = "spline") %>%
  as_tibble() %>%
  bind_cols({caf.mir %>%
      select(id.layer_local_c)}, .) %>%
  select(id.layer_local_c, as.character(rev(new.wavenumbers)))

# Gaps
scans.na.gaps <- caf.mir %>%
  select(-id.layer_local_c) %>%
  apply(., 1, function(x) round(100*(sum(is.na(x)))/(length(x)), 2)) %>%
  tibble(proportion_NA = .) %>%
  bind_cols({caf.mir %>% select(id.layer_local_c)}, .)

# Extreme negative - irreversible erratic patterns
scans.extreme.neg <- caf.mir %>%
  select(-id.layer_local_c) %>%
  apply(., 1, function(x) {round(100*(sum(x < -1, na.rm=TRUE))/(length(x)), 2)}) %>%
  tibble(proportion_lower0 = .) %>%
  bind_cols({caf.mir %>% select(id.layer_local_c)}, .)

# Extreme positive, irreversible erratic patterns
scans.extreme.pos <- caf.mir %>%
  select(-id.layer_local_c) %>%
  apply(., 1, function(x) {round(100*(sum(x > 5, na.rm=TRUE))/(length(x)), 2)}) %>%
  tibble(proportion_higherAbs5 = .) %>%
  bind_cols({caf.mir %>% select(id.layer_local_c)}, .)

# Consistency summary - problematic scans
scans.summary <- scans.na.gaps %>%
  left_join(scans.extreme.neg, by = "id.layer_local_c") %>%
  left_join(scans.extreme.pos, by = "id.layer_local_c")

scans.summary %>%
  select(-id.layer_local_c) %>%
  pivot_longer(everything(), names_to = "check", values_to = "value") %>%
  filter(value > 0) %>%
  group_by(check) %>%
  summarise(count = n())

# Renaming
old.wavenumbers <- seq(600, 4000, by = 2)
new.wavenumbers <- paste0("scan_mir.", old.wavenumbers, "_abs")

caf.mir <- caf.mir %>%
  rename_with(~new.wavenumbers, as.character(old.wavenumbers))

# Preparing metadata
caf.mir.metadata <- caf.mir %>%
  select(id.layer_local_c) %>%
  mutate(id.scan_local_c = id.layer_local_c) %>%
  mutate(scan.mir.date.begin_iso.8601_yyyy.mm.dd = ymd("2014-01-01"),
         scan.mir.date.end_iso.8601_yyyy.mm.dd = ymd("2018-12-31"),
         scan.mir.model.name_utf8_txt = "Bruker Vertex 70 with HTS-XT accessory",
         scan.mir.model.code_any_txt = "Bruker_Vertex_70.HTS.XT",
         scan.mir.method.light.source_any_txt = "",
         scan.mir.method.preparation_any_txt = "",
         scan.mir.license.title_ascii_txt = "CC-BY",
         scan.mir.license.address_idn_url = "https://creativecommons.org/licenses/by/4.0/",
         scan.mir.doi_idf_url = "https://doi.org/10.5281/zenodo.4351254",
         scan.mir.contact.name_utf8_txt = "Laura Summerauer",
         scan.mir.contact.email_ietf_txt = "laura.summerauer@usys.ethz.ch")

# Final preparation
caf.mir.export <- caf.mir.metadata %>%
  left_join(caf.mir, by = "id.layer_local_c") %>%
  mutate_at(vars(starts_with("id.")), as.character)

# Saving version to dataset root dir
soilmir.qs = paste0(dir, "/ossl_mir_v1.2.qs")
qs::qsave(caf.mir.export, soilmir.qs, preset = "high")
```

### Quality control

The final table must be joined as:

- MIR is used as first reference.
- Then it is left joined with the site and soil lab data. This drop data without any scan.

The availabilty of data is summarised below:
```{r bind_test, include=TRUE, echo=TRUE, eval=TRUE}
# Taking a few representative columns for checking the consistency of joins
caf.availability <- caf.mir.export %>%
  select(id.layer_local_c, scan_mir.600_abs) %>%
  left_join({caf.sitedata %>%
      select(id.layer_local_c, layer.upper.depth_usda_cm)}, by = "id.layer_local_c") %>%
  left_join({caf.soildata %>%
      select(id.layer_local_c, ph.h2o_usda.a268_index)}, by = "id.layer_local_c") %>%
  filter(!is.na(id.layer_local_c))

# Availability of information from caf
caf.availability %>%
  mutate_all(as.character) %>%
  pivot_longer(everything(), names_to = "column", values_to = "value") %>%
  filter(!is.na(value)) %>%
  group_by(column) %>%
  summarise(count = n())

# Repeats check - Duplicates are dropped
caf.availability %>%
  mutate_all(as.character) %>%
  select(id.layer_local_c) %>%
  pivot_longer(everything(), names_to = "column", values_to = "value") %>%
  group_by(column, value) %>%
  summarise(repeats = n()) %>%
  group_by(column, repeats) %>%
  summarise(count = n())
```

Plotting sites map:
```{r map, include=TRUE, echo=TRUE, eval=TRUE}
data("World")

points <- caf.sitedata %>%
  filter(!is.na(longitude.point_wgs84_dd)) %>%
  st_as_sf(coords = c('longitude.point_wgs84_dd', 'latitude.point_wgs84_dd'), crs = 4326)

tmap_mode("plot")

tm_shape(World) +
  tm_polygons('#f0f0f0f0', border.alpha = 0.2) +
  tm_shape(points) +
  tm_dots()
```

Soil analytical data summary. Note: many scans could not be linked with the wetchem.
```{r summary, include=TRUE, echo=TRUE, eval=TRUE}
caf.soildata %>%
  mutate(id.layer_local_c = factor(id.layer_local_c)) %>%
  skimr::skim() %>%
  dplyr::select(-numeric.hist, -complete_rate)
```

MIR spectral visualization:
```{r mir_plot, include=TRUE, echo=TRUE, eval=TRUE}
set.seed(1993)
caf.mir %>%
  sample_n(500) %>%
  select(all_of(c("id.layer_local_c")), starts_with("scan_mir.")) %>%
  tidyr::pivot_longer(-all_of(c("id.layer_local_c")),
                      names_to = "wavenumber", values_to = "absorbance") %>%
  dplyr::mutate(wavenumber = gsub("scan_mir.|_abs", "", wavenumber)) %>%
  dplyr::mutate(wavenumber = as.numeric(wavenumber)) %>%
  ggplot(aes(x = wavenumber, y = absorbance, group = id.layer_local_c)) +
  geom_line(alpha = 0.1) +
  scale_x_continuous(breaks = c(600, 1200, 1800, 2400, 3000, 3600, 4000)) +
  labs(x = bquote("Wavenumber"~(cm^-1)), y = "Absorbance") +
  theme_light()
```

```{r}
toc()
rm(list = ls())
gc()
```

## References
